{
 "metadata": {
  "name": "",
  "signature": "sha256:750f936520ad29d646868c0918cc66f0269c132db6d07115fc84dbc9ef29f594"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lab 5. Modelos de Lenguaje para Espa\u00f1ol\n",
      "===============================================\n",
      "Data a utilizar: Noticias Espa\u00f1olas (CESS-ESP Treebank)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables globales"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "STOP = '</s>' # simbolo de fin de oracion\n",
      "RARE = '<R>'  # etiqueta para palabra de baja frecuencia\n",
      "THR = 5       # umbral de baja frecuencia (<=THR -> RARE)\n",
      "\n",
      "stemmer = SnowballStemmer('spanish') # Stemmer para espa\u00f1ol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Funciones de Modelo\n",
      "---------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# funci\u00f3n de preprocesado de texto:\n",
      "#   normaliza palabras y extrae unigramas y bigramas\n",
      "def preprocess_corpus(corpus,vocab,stemming=True):\n",
      "    \"\"\"\n",
      "    corpus: [ [word] ] lista de oraciones. Oracion: lista de palabras\n",
      "    vocab: {word:freq} diccionario de palabra : frecuencia\n",
      "    returns: corpus_preprocesado, unigramas, bigramas\n",
      "    \"\"\"\n",
      "    unigrams = []\n",
      "    bigrams = []\n",
      "    new_corpus = []\n",
      "    for sent in corpus:\n",
      "        new_sent = []\n",
      "        prev_word = sent[0]\n",
      "        for i,word in enumerate(sent):\n",
      "            new_word = ''\n",
      "            ####\n",
      "            if word in vocab:\n",
      "                if vocab[word]>THR:\n",
      "                    if stemming:\n",
      "                        new_word = stemmer.stem(word)\n",
      "                    else:\n",
      "                        new_word = word\n",
      "                else:\n",
      "                    new_word = RARE\n",
      "            else:\n",
      "                new_word = RARE\n",
      "            ####\n",
      "            new_sent.append(new_word)\n",
      "            # hallando bigramas\n",
      "            ####\n",
      "            if i>0:\n",
      "                bigrams.append( (prev_word,new_word) )\n",
      "            ####\n",
      "            prev_word = new_word\n",
      "        # hallando unigramas\n",
      "        ####\n",
      "        unigrams.extend(new_sent)\n",
      "        # agregar terminos STOP\n",
      "        ####\n",
      "        unigrams.append(STOP)\n",
      "        bigrams.append( (new_sent[-1],STOP) )\n",
      "        ####\n",
      "        new_corpus.append(new_sent)\n",
      "        \n",
      "    return new_corpus,unigrams,bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidades P(wi) y P(wi|w_{i-1})\n",
      "def language_model(unigrams,bigrams):\n",
      "    \"\"\"\n",
      "    unigrams: lista de unigramas\n",
      "    bigrams: liste de bigramas [pares (w_{i-1},w_i)]\n",
      "    return: P(wi), P(wi|w_{i-1})\n",
      "    \"\"\"\n",
      "    freq_ug = nltk.FreqDist(unigrams)\n",
      "    N_ug = len(unigrams)\n",
      "    prob_unigrams = { word:freq/N_ug for word,freq in freq_ug.items() }\n",
      "    \n",
      "    freq_bg = nltk.ConditionalFreqDist(bigrams)\n",
      "    cprob_bigrams = {}\n",
      "    \n",
      "    for w_prev,_ in freq_bg.items():\n",
      "        prob_wp = {}\n",
      "        for w_curr in freq_ug.keys():\n",
      "            if w_curr in freq_bg[w_prev]:\n",
      "                prob_wp[w_curr] = freq_bg[w_prev][w_curr] / freq_ug[w_prev]\n",
      "            else:\n",
      "                prob_wp[w_curr] = 0\n",
      "        cprob_bigrams[w_prev] = prob_wp\n",
      "        \n",
      "    return prob_unigrams,cprob_bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidad logar\u00edtmica de una oraci\u00f3n\n",
      "def log_prob_sentence_bigram(sent,lm_ug,lm_bg):\n",
      "    \"\"\"\n",
      "    sent: oracion con 'm' palabras. [word]\n",
      "    lm_ug: probabilidades de unigramas {wi: P(wi)}\n",
      "    lm_bg: probabilidades de bigramas {w_{i-1}: P(wi|w_{i-1}}\n",
      "    return: log(P(w0)) + Sum_{i=1,m}( log(P(wi|w_{i-1})) ) + log(P(STOP|w_m))\n",
      "    \"\"\"\n",
      "    log_prob = 0\n",
      "    ####\n",
      "    ####\n",
      "               \n",
      "    return log_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_prob_sentence(sent,lm_ug):\n",
      "    log_prob = 0\n",
      "    ###\n",
      "    for token in sent:\n",
      "        log_prob += np.log( lm_ug[token] )\n",
      "    ###\n",
      "    return log_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Bigramas\n",
      "def perplexity_bigram(corpus,lm_ug,lm_bg):\n",
      "    L = 0\n",
      "    N_corpus = 1\n",
      "    for sent in corpus:\n",
      "        #L += \n",
      "        #N_corpus += \n",
      "        continue\n",
      "    \n",
      "    return np.power(2,-L/N_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Unigramas\n",
      "def perplexity_unigram(corpus,lm_ug):\n",
      "    total_unigrams = 1\n",
      "    L = 0\n",
      "    for sent in corpus:\n",
      "        L += log_prob_sentence(sent,lm_ug)\n",
      "        total_unigrams += len(sent)\n",
      "        \n",
      "        \n",
      "    return np.power(2,-L/total_unigrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "==========================================================================================================\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lectura y separaci\u00f3n de data\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lectura del corpus\n",
      "len_corpus = 6030\n",
      "corpus = nltk.corpus.cess_esp.sents()[:len_corpus]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Dividiendo en training y testing\n",
      "test_perc = 0.2\n",
      "train_ids,test_ids = train_test_split(range(len_corpus),test_size=test_perc,random_state=42)\n",
      "\n",
      "train_corpus,test_corpus = [],[]\n",
      "for _id in train_ids:\n",
      "    train_corpus.append(corpus[_id])\n",
      "for _id in test_ids:\n",
      "    test_corpus.append(corpus[_id])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Training size:\",len(train_corpus))\n",
      "print(\"Testing size:\",len(test_corpus))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training size: 4824\n",
        "Testing size: 1206\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obteniendo vocabulario\n",
      "-----------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obteniedo vocabulario de data de entrenamiento\n",
      "train_words = []\n",
      "for sent in train_corpus:\n",
      "    # pasando a minuscula\n",
      "\ttrain_words.extend([word.lower() for word in sent])\n",
      "\n",
      "train_vocab = nltk.FreqDist(train_words)\n",
      "del train_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Preprocesando data\n",
      "--------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemming = False # hacer stemming?\n",
      "\n",
      "# Preprocesar data de entrenamiento\n",
      "train,U,B = preprocess_corpus(train_corpus,train_vocab,stemming=stemming)\n",
      "# Preprocesar data de testeo\n",
      "test,_,_ = preprocess_corpus(test_corpus,train_vocab,stemming=stemming)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Entrenando modelo\n",
      "--------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ajustar modelo en training data\n",
      "lm_ug,lm_bg = language_model(U,B)\n",
      "del U\n",
      "del B\n",
      "\n",
      "# Prueba\n",
      "PP= perplexity_unigram(train,lm_ug)\n",
      "#P = perplexity_bigram(train,lm_ug,lm_bg)\n",
      "print(\"PP training set: %.2f\" % PP)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PP training set: 24.43\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testeando\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prueba en Testing data\n",
      "PP_test = perplexity_unigram(test,lm_ug)\n",
      "#PP_test = perplexity_bigram(test,lm_ug,lm_bg)\n",
      "print(\"Test: %.2f\" % PP_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test: 22.09\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    }
   ],
   "metadata": {}
  }
 ]
}