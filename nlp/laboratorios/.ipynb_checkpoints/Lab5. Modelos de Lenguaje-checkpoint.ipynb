{
 "metadata": {
  "name": "",
  "signature": "sha256:98ee119620e0ebd00c73f4530cf985832dfdf692f6130f7fbbb73eecb9ed8913"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lab 5. Modelos de Lenguaje para Espa\u00f1ol\n",
      "===============================================\n",
      "Data a utilizar: Noticias Espa\u00f1olas (CESS-ESP Treebank)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables globales"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "STOP = '</s>' # simbolo de fin de oracion\n",
      "RARE = '<R>'  # etiqueta para palabra de baja frecuencia\n",
      "THR = 5       # umbral de baja frecuencia (<=THR -> RARE)\n",
      "\n",
      "stemmer = SnowballStemmer('spanish') # Stemmer para espa\u00f1ol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Funciones de Modelo\n",
      "---------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# funci\u00f3n de preprocesado de texto:\n",
      "#   normaliza palabras y extrae unigramas y bigramas\n",
      "def preprocess_corpus(corpus,vocab,stemming=True):\n",
      "    \"\"\"\n",
      "    corpus: [ [word] ] lista de oraciones. Oracion: lista de palabras\n",
      "    vocab: {word:freq} diccionario de palabra : frecuencia\n",
      "    returns: corpus_preprocesado, unigramas, bigramas\n",
      "    \"\"\"\n",
      "    unigrams = []\n",
      "    bigrams = []\n",
      "    new_corpus = []\n",
      "    for sent in corpus:\n",
      "        new_sent = []\n",
      "        prev_word = sent[0]\n",
      "        for i,word in enumerate(sent):\n",
      "            new_word = ''\n",
      "            ####\n",
      "            ####\n",
      "            new_sent.append(new_word)\n",
      "            # hallando bigramas\n",
      "            ####\n",
      "            ####\n",
      "            prev_word = new_word\n",
      "        # hallando unigramas\n",
      "        ####\n",
      "        \n",
      "        # agregar terminos STOP\n",
      "        ####\n",
      "        ####\n",
      "        new_corpus.append(new_sent)\n",
      "        \n",
      "    return new_corpus,unigrams,bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidades P(wi) y P(wi|w_{i-1})\n",
      "def language_model(unigrams,bigrams):\n",
      "    \"\"\"\n",
      "    unigrams: lista de unigramas\n",
      "    bigrams: liste de bigramas [pares (w_{i-1},w_i)]\n",
      "    return: P(wi), P(wi|w_{i-1})\n",
      "    \"\"\"\n",
      "    freq_ug = nltk.FreqDist(unigrams)\n",
      "    prob_unigrams = {}\n",
      "    \n",
      "    freq_bg = nltk.ConditionalFreqDist(bigrams)\n",
      "    cprob_bigrams = {}    \n",
      "        \n",
      "    return prob_unigrams,cprob_bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidad logar\u00edtmica de una oraci\u00f3n\n",
      "def log_prob_sentence_bigram(sent,lm_ug,lm_bg):\n",
      "    \"\"\"\n",
      "    sent: oracion con 'm' palabras. [word]\n",
      "    lm_ug: probabilidades de unigramas {wi: P(wi)}\n",
      "    lm_bg: probabilidades de bigramas {w_{i-1}: P(wi|w_{i-1}}\n",
      "    return: log(P(w0)) + Sum_{i=1,m}( log(P(wi|w_{i-1})) ) + log(P(STOP|w_m))\n",
      "    \"\"\"\n",
      "    log_prob = 0\n",
      "    ####\n",
      "    ####\n",
      "               \n",
      "    return log_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def log_prob_sentence(sent,lm_ug):\n",
      "    log_prob = 0\n",
      "    ###\n",
      "    ###\n",
      "    return log_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Bigramas\n",
      "def perplexity_bigram(corpus,lm_ug,lm_bg):\n",
      "    L = 0\n",
      "    N_corpus = 1\n",
      "    for sent in corpus:\n",
      "        #L += \n",
      "        #N_corpus += \n",
      "        continue\n",
      "    \n",
      "    return np.power(2,-L/N_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Unigramas\n",
      "def perplexity_unigram(corpus,lm_ug):\n",
      "    total_unigrams = 1\n",
      "    L = 0\n",
      "    for sent in corpus:\n",
      "        #L += \n",
      "        #total_unigrams += \n",
      "        continue\n",
      "        \n",
      "    return np.power(2,-L/total_unigrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "==========================================================================================================\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lectura y separaci\u00f3n de data\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lectura del corpus\n",
      "len_corpus = 6030\n",
      "corpus = nltk.corpus.cess_esp.sents()[:len_corpus]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Dividiendo en training y testing\n",
      "test_perc = 0.2\n",
      "train_ids,test_ids = train_test_split(range(len_corpus),test_size=test_perc,random_state=42)\n",
      "\n",
      "train_corpus,test_corpus = [],[]\n",
      "for _id in train_ids:\n",
      "    train_corpus.append(corpus[_id])\n",
      "for _id in test_ids:\n",
      "    test_corpus.append(corpus[_id])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Training size:\",len(train_corpus))\n",
      "print(\"Testing size:\",len(test_corpus))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training size: 4824\n",
        "Testing size: 1206\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obteniendo vocabulario\n",
      "-----------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obteniedo vocabulario de data de entrenamiento\n",
      "train_words = []\n",
      "for sent in train_corpus:\n",
      "    # pasando a minuscula\n",
      "\ttrain_words.extend([word.lower() for word in sent])\n",
      "\n",
      "train_vocab = nltk.FreqDist(train_words)\n",
      "del train_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_vocab.most_common()[100:110]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[('esa', 98),\n",
        " ('estado', 95),\n",
        " ('primera', 90),\n",
        " ('pa\u00edses', 89),\n",
        " ('tiempo', 88),\n",
        " ('unos', 87),\n",
        " ('hacer', 87),\n",
        " ('antes', 87),\n",
        " ('primer', 86),\n",
        " ('eso', 86)]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Preprocesando data\n",
      "--------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemming = False # hacer stemming?\n",
      "\n",
      "# Preprocesar data de entrenamiento\n",
      "train,U,B = preprocess_corpus(train_corpus,train_vocab,stemming=stemming)\n",
      "# Preprocesar data de testeo\n",
      "test,_,_ = preprocess_corpus(test_corpus,train_vocab,stemming=stemming)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Entrenando modelo\n",
      "--------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ajustar modelo en training data\n",
      "lm_ug,lm_bg = language_model(U,B)\n",
      "del U\n",
      "del B\n",
      "\n",
      "# Prueba\n",
      "PP= perplexity_unigram(train,lm_ug)\n",
      "#P = perplexity_bigram(train,lm_ug,lm_bg)\n",
      "print(\"PP training set: %.2f\" % PP)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PP training set: 1.00\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testeando\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prueba en Testing data\n",
      "PP_test = perplexity_unigram(test,lm_ug)\n",
      "#PP_test = perplexity_bigram(test,lm_ug,lm_bg)\n",
      "print(\"Test: %.2f\" % PP_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test: 1.00\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}