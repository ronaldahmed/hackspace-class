{
 "metadata": {
  "name": "",
  "signature": "sha256:f04e8352299963df0eb209801f171cd5bb476ca0d295e243410f3ef39b92e9aa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lab 5. Modelos de Lenguaje para Espa\u00f1ol\n",
      "===============================================\n",
      "Data a utilizar: Noticias Espa\u00f1olas (CESS-ESP Treebank)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables globales"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "STOP = '</s>' # simbolo de fin de oracion\n",
      "RARE = '<R>'  # etiqueta para palabra de baja frecuencia\n",
      "THR = 5       # umbral de baja frecuencia (<=THR -> RARE)\n",
      "\n",
      "stemmer = SnowballStemmer('spanish') # Stemmer para espa\u00f1ol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Funciones de Modelo\n",
      "---------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# funci\u00f3n de preprocesado de texto:\n",
      "#   normaliza palabras y extrae unigramas y bigramas\n",
      "def preprocess_corpus(corpus,vocab):\n",
      "    \"\"\"\n",
      "    corpus: [ [word] ] lista de oraciones. Oracion: lista de palabras\n",
      "    vocab: {word:freq} diccionario de palabra : frecuencia\n",
      "    returns: corpus_preprocesado, unigramas, bigramas\n",
      "    \"\"\"\n",
      "    unigrams = []\n",
      "    bigrams = []\n",
      "    new_corpus = []\n",
      "    for sent in corpus:\n",
      "        new_sent = []\n",
      "        \n",
      "    return new_corpus,unigrams,bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidades P(wi) y P(wi|w_{i-1})\n",
      "def language_model(unigrams,bigrams):\n",
      "    \"\"\"\n",
      "    unigrams: lista de unigramas\n",
      "    bigrams: liste de bigramas [pares (w_{i-1},w_i)]\n",
      "    return: P(wi), P(wi|w_{i-1})\n",
      "    \"\"\"\n",
      "    prob_unigrams =\n",
      "    cprob_bigrams =\n",
      "    return prob_unigrams,cprob_bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidad logar\u00edtmica de una oraci\u00f3n\n",
      "def log_prob_sentence(sent,lm_ug,lm_bg):\n",
      "    \"\"\"\n",
      "    sent: oracion con 'm' palabras. [word]\n",
      "    lm_ug: probabilidades de unigramas {wi: P(wi)}\n",
      "    lm_bg: probabilidades de bigramas {w_{i-1}: P(wi|w_{i-1}}\n",
      "    return: log(P(w0)) + Sum_{i=1,m}( log(P(wi|w_{i-1})) ) + log(P(STOP|w_m))\n",
      "    \"\"\"\n",
      "    log_prob = \n",
      "    return log_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Bigramas\n",
      "def perplexity_bigram(corpus,lm_ug,lm_bg):\n",
      "    L = 0\n",
      "    for sent in corpus:\n",
      "        L +=\n",
      "    return np.power(2,-L/len_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Bigramas\n",
      "def perplexity_unigram(corpus,lm_ug):\n",
      "    L = 0\n",
      "    for sent in corpus:\n",
      "        L +=\n",
      "    return np.power(2,-L/len_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Corriendo el Modelo\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lectura del corpus\n",
      "len_corpus = 6030\n",
      "corpus = nltk.corpus.cess_esp.sents()[:len_corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Dividiendo en training y testing\n",
      "test_perc = 0.2\n",
      "train_ids,test_ids = train_test_split(range(len_corpus),test_size=test_perc,random_state=42)\n",
      "\n",
      "train_corpus,test_corpus = [],[]\n",
      "for _id in train_ids:\n",
      "\ttrain_corpus.append(corpus[_id])\n",
      "for _id in test_ids:\n",
      "\ttest_corpus.append(corpus[_id])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obteniedo vocabulario de data de entrenamiento\n",
      "train_words = []\n",
      "for sent in train_corpus:\n",
      "\ttrain_words.extend([word.lower() for word in sent])\n",
      "\n",
      "train_vocab = nltk.FreqDist(train_words)\n",
      "del train_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ajustar modelo en training data\n",
      "# hacer stemming?\n",
      "stemming = False\n",
      "train,U,B = preprocess_corpus(train_corpus,train_vocab,stemming=stemming)\n",
      "lm_ug,lm_bg = language_model(U,B)\n",
      "del U\n",
      "del B\n",
      "\n",
      "# Prueba\n",
      "#PP= perplexity_unigram(train,lm_ug)\n",
      "PP = perplexity(train,lm_ug,lm_bg)\n",
      "print(\"PP training set: %.2f\" % PP)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prueba en Testing data\n",
      "test,_,_ = preprocess_corpus(test_corpus,train_vocab,stemming=stemming)\n",
      "\n",
      "#PP_test = perplexity_unigram(test,lm_ug)\n",
      "PP_test = perplexity(test,lm_ug,lm_bg)\n",
      "print(\"Test: %.2f\" % PP_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}