{
 "metadata": {
  "name": "",
  "signature": "sha256:fbc472f98cbe404b0e7b92995bc48e433a01243b9c751a870a6f5fc958164c0d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lab 5. Modelos de Lenguaje para Espa\u00f1ol\n",
      "===============================================\n",
      "Data a utilizar: Noticias Espa\u00f1olas (CESS-ESP Treebank)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Variables globales"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "STOP = '</s>' # simbolo de fin de oracion\n",
      "RARE = '<R>'  # etiqueta para palabra de baja frecuencia\n",
      "THR = 5       # umbral de baja frecuencia (<=THR -> RARE)\n",
      "\n",
      "stemmer = SnowballStemmer('spanish') # Stemmer para espa\u00f1ol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Funciones de Modelo\n",
      "---------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# funci\u00f3n de preprocesado de texto:\n",
      "#   normaliza palabras y extrae unigramas y bigramas\n",
      "def preprocess_corpus(corpus,vocab,stemming=True):\n",
      "    \"\"\"\n",
      "    corpus: [ [word] ] lista de oraciones. Oracion: lista de palabras\n",
      "    vocab: {word:freq} diccionario de palabra : frecuencia\n",
      "    returns: corpus_preprocesado, unigramas, bigramas\n",
      "    \"\"\"\n",
      "    unigrams = []\n",
      "    bigrams = []\n",
      "    new_corpus = []\n",
      "    for sent in corpus:\n",
      "        new_sent = []\n",
      "        prev_word = sent[0]\n",
      "        for i,word in enumerate(sent):\n",
      "            new_word = ''\n",
      "            if word not in vocab or vocab[word]<=THR:\n",
      "                new_word = RARE\n",
      "            else:\n",
      "                if stemming:\n",
      "                    new_word = stemmer.stem(word)\n",
      "                else:\n",
      "                    new_word = word\n",
      "            new_sent.append(new_word)\n",
      "            # hallando bigramas\n",
      "            if i>0:\n",
      "                bigrams.append( (prev_word,new_word) )\n",
      "            prev_word = new_word\n",
      "        # hallando unigramas\n",
      "        unigrams.extend(new_sent) # [u0,u1....un]\n",
      "        # agregar terminos STOP\n",
      "        bigrams.append( (unigrams[-1],STOP) )\n",
      "        unigrams.append(STOP)\n",
      "        new_corpus.append(new_sent)\n",
      "        \n",
      "    return new_corpus,unigrams,bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preprocess_corpus([['a','b','c'],['a','d']], {'a':6,'b':6,'c':1,'d':1})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "([['a', 'b', '<R>'], ['a', '<R>']],\n",
        " ['a', 'b', '<R>', '</s>', 'a', '<R>', '</s>'],\n",
        " [('a', 'b'), ('b', '<R>'), ('<R>', '</s>'), ('a', '<R>'), ('<R>', '</s>')])"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidades P(wi) y P(wi|w_{i-1})\n",
      "def language_model(unigrams,bigrams):\n",
      "    \"\"\"\n",
      "    unigrams: lista de unigramas\n",
      "    bigrams: liste de bigramas [pares (w_{i-1},w_i)]\n",
      "    return: P(wi), P(wi|w_{i-1})\n",
      "    \"\"\"\n",
      "    freq_ug = nltk.FreqDist(unigrams)\n",
      "    N_ug = sum([freq for freq in freq_ug.values()])\n",
      "    prob_unigrams = dict( zip(freq_ug.keys(),\\\n",
      "                              [freq_w/N_ug for freq_w in freq_ug.values()]) )\n",
      "    \n",
      "    freq_bg = nltk.ConditionalFreqDist(bigrams)\n",
      "    cprob_bigrams = {}\n",
      "    for wi_1 in freq_bg.keys():\n",
      "        cprob_bigrams[wi_1] = {}\n",
      "        for wi in freq_ug.keys():\n",
      "            if wi in freq_bg[wi_1]:\n",
      "                cprob_bigrams[wi_1][wi] = 1.0*freq_bg[wi_1][wi] / freq_ug[wi_1]\n",
      "            else:\n",
      "                cprob_bigrams[wi_1][wi] = 0.0\n",
      "        \n",
      "    return prob_unigrams,cprob_bigrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de probabilidad logar\u00edtmica de una oraci\u00f3n\n",
      "def log_prob_sentence(sent,lm_ug,lm_bg):\n",
      "    \"\"\"\n",
      "    sent: oracion con 'm' palabras. [word]\n",
      "    lm_ug: probabilidades de unigramas {wi: P(wi)}\n",
      "    lm_bg: probabilidades de bigramas {w_{i-1}: P(wi|w_{i-1}}\n",
      "    return: log(P(w0)) + Sum_{i=1,m}( log(P(wi|w_{i-1})) ) + log(P(STOP|w_m))\n",
      "    \"\"\"\n",
      "    log_prob = np.log(lm_ug[sent[0]]+1e-8) + \\\n",
      "               sum([ np.log(lm_bg[sent[i-1]][sent[i]]+1e-8)   \n",
      "                        for i in range(1,len(sent))        ])  +\\\n",
      "               np.log( lm_bg[sent[-1]][STOP]+1e-8)\n",
      "               \n",
      "    return log_prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Bigramas\n",
      "def perplexity_bigram(corpus,lm_ug,lm_bg):\n",
      "    L = 0\n",
      "    N_corpus = 0\n",
      "    for sent in corpus:\n",
      "        L += log_prob_sentence(sent,lm_ug,lm_bg)\n",
      "        N_corpus += len(sent)+1\n",
      "    \n",
      "    return np.power(2,-L/N_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# C\u00e1lculo de Perplexity para Modelo de Unigramas\n",
      "def perplexity_unigram(corpus,lm_ug):\n",
      "    total_unigrams = 0\n",
      "    L = 0\n",
      "    for sent in corpus:\n",
      "        # log prob de una oracion\n",
      "        L += sum([np.log(lm_ug[ug]+1e-12) for ug in sent])\n",
      "        total_unigrams += len(sent)\n",
      "    #L+= lm_ug[STOP]\n",
      "    return np.power(2,-L/total_unigrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Corriendo el Modelo\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lectura del corpus\n",
      "len_corpus = 6030\n",
      "corpus = nltk.corpus.cess_esp.sents()[:len_corpus]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Dividiendo en training y testing\n",
      "test_perc = 0.2\n",
      "train_ids,test_ids = train_test_split(range(len_corpus),test_size=test_perc,random_state=42)\n",
      "\n",
      "train_corpus,test_corpus = [],[]\n",
      "for _id in train_ids:\n",
      "\ttrain_corpus.append(corpus[_id])\n",
      "for _id in test_ids:\n",
      "\ttest_corpus.append(corpus[_id])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(test_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1206"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obteniedo vocabulario de data de entrenamiento\n",
      "train_words = []\n",
      "for sent in train_corpus:\n",
      "    # pasando a minuscula\n",
      "\ttrain_words.extend([word.lower() for word in sent])\n",
      "\n",
      "train_vocab = nltk.FreqDist(train_words)\n",
      "del train_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_vocab.most_common()[100:110]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[('esa', 98),\n",
        " ('estado', 95),\n",
        " ('primera', 90),\n",
        " ('pa\u00edses', 89),\n",
        " ('tiempo', 88),\n",
        " ('antes', 87),\n",
        " ('unos', 87),\n",
        " ('hacer', 87),\n",
        " ('eso', 86),\n",
        " ('primer', 86)]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ajustar modelo en training data\n",
      "# hacer stemming?\n",
      "stemming = False\n",
      "train,U,B = preprocess_corpus(train_corpus,train_vocab,stemming=stemming)\n",
      "lm_ug,lm_bg = language_model(U,B)\n",
      "del U\n",
      "del B\n",
      "\n",
      "# Prueba\n",
      "#PP= perplexity_unigram(train,lm_ug)\n",
      "PP = perplexity_bigram(train,lm_ug,lm_bg)\n",
      "print(\"PP training set: %.2f\" % PP)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PP training set: 9.34\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prueba en Testing data\n",
      "test,_,_ = preprocess_corpus(test_corpus,train_vocab,stemming=stemming)\n",
      "\n",
      "#PP_test = perplexity_unigram(test,lm_ug)\n",
      "PP_test = perplexity_bigram(test,lm_ug,lm_bg)\n",
      "print(\"Test: %.2f\" % PP_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test: 26.69\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}